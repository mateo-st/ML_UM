{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53681f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nClusters(n, dataset):\n",
    "    \n",
    "    # DESCRIPTION: \n",
    "    # Function that clusterizes some dataset.\n",
    "    \n",
    "    # INPUTS:\n",
    "    # n (int): Number of clusters\n",
    "    # dataset (pd Dataframe): Clients dataset after a PCA for dimensionality reduction\n",
    "    # modelType (str): string indicating the choice of model\n",
    "    \n",
    "    # OUTPUTS:\n",
    "    # model (object): the sklearn model of kmeans already \"trained\", used for\n",
    "    # obtaining information\n",
    "    # dataset (pd dataframe): the fitted dataset\n",
    "    # clusters_df (pandas dataframe): the input dataframe but with cluster id aggregated\n",
    "    # assign (pandas dataframe): the original first dataframe with original features,\n",
    "    # but with cluster id aggregated\n",
    "    \n",
    "    model = KMeans(n_clusters = n, random_state = 42) # max iters is set to 300 by default\n",
    "    model.fit(dataset)\n",
    "\n",
    "    # Assign a cluster id to the original df.\n",
    "    clusters_df = pd.concat([dataset, pd.Series(model.labels_)], axis = 1) # concatenate labels to pca df\n",
    "    clusters_df.columns = np.concatenate((dataset.columns.values, ['CLUSTER ID']), axis = 0) #add the \"cluster id\" columna\n",
    "    #clusters_df = pd.concat([CUST_ID, clusters_df], axis = 1) #add the \"customer id\" df at the begining.\n",
    "    print(f'The model assigned theese values:')\n",
    "        \n",
    "    # Recovering previous features for discussion:\n",
    "    #assign = pd.concat([client_data, pd.Series(model.labels_)], axis = 1) # concatenate labels to pca df\n",
    "    #assign.columns  = np.concatenate((client_data.columns.values, ['CLUSTER ID']), axis = 0) #add the \"cluster id\" columna\n",
    "    print(clusters_df['CLUSTER ID'].value_counts())\n",
    "        \n",
    "    return clusters_df, model\n",
    "    \n",
    "def elbobMethod(max_clusters):\n",
    "    # Elbow method\n",
    "\n",
    "    elbow_points = []\n",
    "    #max_clusters = len(dataset_blood_scaled)\n",
    "    n_clust = [i+2 for i in range(max_clusters)]\n",
    "\n",
    "    for num in n_clust:\n",
    "        kmeans = KMeans(n_clusters = num, random_state = 42)\n",
    "        kmeans.fit(dataset_blood_scaled)\n",
    "        elbow_points.append(kmeans.inertia_)\n",
    "\n",
    "    plt.plot(n_clust, elbow_points, 'bo-')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def getMeansFromCluster(assigned_df, n_clusters):\n",
    "    \n",
    "    # DESCRIPTION:\n",
    "    # Function that outputs statistics of dataset with assigned cluster id\n",
    "    # after some clusterization\n",
    "    \n",
    "    # INPUTS:\n",
    "    # assigned_df (pandas dataframe): dataframe containinng the original\n",
    "    # features before pca and a cluster id\n",
    "    # n_clusters (int): number of clusters \n",
    "    \n",
    "    # OUTPUTS:\n",
    "    # statistics (pandas dataframe): dataframe containing the mean of\n",
    "    # every feature grouped by cluster\n",
    "    \n",
    "    # HAY QUE CAMBIAR ESTO\n",
    "    balance = pd.DataFrame(assigned_df.groupby(['CLUSTER ID']).BALANCE.mean())\n",
    "    balance_frequency= pd.DataFrame(assigned_df.groupby(['CLUSTER ID']).BALANCE_FREQUENCY.mean())\n",
    "    purchases= pd.DataFrame(assigned_df.groupby(['CLUSTER ID']).PURCHASES.mean())\n",
    "    oneoff_purchases = pd.DataFrame(assigned_df.groupby(['CLUSTER ID']).ONEOFF_PURCHASES.mean())\n",
    "    installments_purchases = pd.DataFrame(assigned_df.groupby(['CLUSTER ID']).INSTALLMENTS_PURCHASES.mean())\n",
    "    cash_advance = pd.DataFrame(assigned_df.groupby(['CLUSTER ID']).CASH_ADVANCE.mean())\n",
    "    purchase_freq = pd.DataFrame(assigned_df.groupby(['CLUSTER ID']).PURCHASES_FREQUENCY.mean())\n",
    "    oneoff_purchase_freq = pd.DataFrame(assigned_df.groupby(['CLUSTER ID']).ONEOFF_PURCHASES_FREQUENCY.mean()) \n",
    "    purchases_installments_freq = pd.DataFrame(assigned_df.groupby(['CLUSTER ID']).PURCHASES_INSTALLMENTS_FREQUENCY.mean()) \n",
    "    cash_advance_freq = pd.DataFrame(assigned_df.groupby(['CLUSTER ID']).CASH_ADVANCE_FREQUENCY.mean()) \n",
    "    cash_advance_trx = pd.DataFrame(assigned_df.groupby(['CLUSTER ID']).CASH_ADVANCE_TRX.mean())\n",
    "    purchases_trx = pd.DataFrame(assigned_df.groupby(['CLUSTER ID']).PURCHASES_TRX.mean())\n",
    "    credit_limit = pd.DataFrame(assigned_df.groupby(['CLUSTER ID']).CREDIT_LIMIT.mean())\n",
    "    payments = pd.DataFrame(assigned_df.groupby(['CLUSTER ID']).PAYMENTS.mean())\n",
    "    min_paiments = pd.DataFrame(assigned_df.groupby(['CLUSTER ID']).MINIMUM_PAYMENTS.mean())\n",
    "    pcr_full_paiments = pd.DataFrame(assigned_df.groupby(['CLUSTER ID']).PRC_FULL_PAYMENT.mean()) \n",
    "    tenure = pd.DataFrame(assigned_df.groupby(['CLUSTER ID']).TENURE.mean()) \n",
    "\n",
    "    statistics = pd.concat([pd.Series([i for i in range(n_clusters)]),balance,balance_frequency, purchases, oneoff_purchases, installments_purchases,cash_advance,purchase_freq,oneoff_purchase_freq,purchases_installments_freq,cash_advance_freq,cash_advance_trx,purchases_trx,credit_limit,payments,min_paiments,pcr_full_paiments,tenure], axis=1)\n",
    "    statistics = statistics.rename(columns = {0:'CLUSTER ID'}) #correct the number of cluster id column\n",
    "    return statistics\n",
    "\n",
    "\n",
    "\n",
    "def plotNdimensions(n,n_clusters, dataset,model, model_type): \n",
    "    \n",
    "    # DESCRIPTION:\n",
    "    # Function that given a fitted dataset, plots the clustering result\n",
    "    # in order to do this, we perform a PCA to reduce dimensionality.\n",
    "    \n",
    "    # INPUTS:\n",
    "    # n (int): number of dimensions to plot (number of components of visualization PCA)\n",
    "    # dataset (sklearn object): ALREADY fitted dataset of 6 components\n",
    "    # model (sklearn object): model type, only used to get labels for plot\n",
    "    # model_type (str): string indicating the model type,\n",
    "    # only used for fancy automatic titles\n",
    "    \n",
    "    # OUTPUTS:\n",
    "    # No outputs\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = [10, 7]\n",
    "    \n",
    "    # pca to lower dimension to n\n",
    "    n_components = n\n",
    "    pca_final = PCA(n_components = n_components)\n",
    "    pca_final.fit(dataset)  \n",
    "    \n",
    "    # aux df for plotting\n",
    "    visualization = pd.DataFrame(pca_final.fit_transform(dataset), columns = [str(i) for i in range(n)])\n",
    "    visualization = pd.concat([visualization, pd.Series(model.labels_)], axis = 1) # add the labels\n",
    "    visualization.columns = np.concatenate(([str(i+1) for i in range(n)],['CLUSTER ID']), axis = 0)   \n",
    "    \n",
    "    if n == 3:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "        x = visualization['1'].values.astype(float)\n",
    "        y = visualization['2'].values.astype(float)\n",
    "        z = visualization['3'].values.astype(float)\n",
    "\n",
    "        ax.scatter(x,y,z, c=visualization[\"CLUSTER ID\"], s=40) #, cmap=\"RdBu\")\n",
    "        \n",
    "        plt.title(f'3D visualization for: {n_clusters} clusters, using: {model_type} clustering')\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_zticklabels([])\n",
    "        \n",
    "        ax.set_xlabel('PC1', fontweight ='bold')\n",
    "        ax.set_ylabel('PC2', fontweight ='bold')\n",
    "        ax.set_zlabel('PC3', fontweight ='bold')\n",
    "      \n",
    "        plt.show()\n",
    "    \n",
    "    elif n == 2:\n",
    "        \n",
    "        sns.scatterplot(x='1',y='2',hue='CLUSTER ID',legend='full',data=visualization).set(title=f'2D visualization for: {n_clusters} clusters, using: {model_type} clustering')\n",
    "\n",
    "    else:\n",
    "        print(\"The human brain can only interpret 2 or 3 dimensions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
